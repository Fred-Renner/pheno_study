{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import collections\n",
    "import getopt, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linspace\n",
    "import pandas\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ROOT\n",
    "import root_numpy\n",
    "from ROOT import gSystem\n",
    "from root_numpy import root2array, array2tree\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import plot_model\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDict(collections.OrderedDict):\n",
    "    def __missing__(self, key):\n",
    "        val = self[key] = MyDict()\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTreeName = \"preselection\"\n",
    "fileListLocation = \"../datasets_to_append/\"\n",
    "nnLocation = \"/home/paredes/pheno/testnn/pheno_study/analysis/neuralnet/train_all_jets\"\n",
    "inFileList = \"test_append.txt\"\n",
    "#for testing only\n",
    "analysis = \"boosted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "branchList = [\"pT_hh\",\n",
    "              \"nMuon\", \"nElec\",\n",
    "              \"h1_M\", \"h1_Pt\", \"h1_Eta\", \"h1_Phi\", \"h1_j1_j2_dR\",\n",
    "              \"h2_M\", \"h2_Pt\", \"h2_Eta\", \"h2_Phi\", \"h2_j1_j2_dR\",\n",
    "              \"h1_j1_M\", \"h1_j1_Pt\", \"h1_j1_Eta\", \"h1_j1_Phi\",\n",
    "              \"h1_j2_M\", \"h1_j2_Pt\", \"h1_j2_Eta\", \"h1_j2_Phi\",\n",
    "              \"h2_j1_M\", \"h2_j1_Pt\", \"h2_j1_Eta\", \"h2_j1_Phi\",\n",
    "              \"h2_j2_M\", \"h2_j2_Pt\", \"h2_j2_Eta\", \"h2_j2_Phi\",\n",
    "              \"muon1_M\", \"muon1_Pt\", \"muon1_Eta\", \"muon1_Phi\",\n",
    "              \"elec1_M\", \"elec1_Pt\", \"elec1_Eta\", \"elec1_Phi\",\n",
    "              \"met_Et\", \"met_Phi\",\n",
    "              \"h1_j1_BTag\",\"h1_j2_BTag\",\"h2_j1_BTag\",\"h2_j2_BTag\",\n",
    "              \"mc_sf\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/paredes/pheno/testnn/pheno_study/utilities/SplitROOT/OxHHPh_06May2019_MG5_262_Py8_14TeV_NNPDF30NLO_Dlph3_pp2hh_4b_HeavyHiggsTHDM_TopYuk_1.0_SlfCoup_1.0_merged_ntup.root.boosted_0.root 12119 events found\n"
     ]
    }
   ],
   "source": [
    "f = open(inFileList,\"r\")\n",
    "for line in f:\n",
    "    # create a dictionary to store scores for all networks and event types\n",
    "    scoreBranch = MyDict()\n",
    " \n",
    "    inFilepath = line.rstrip()\n",
    "    # Load the input file and grab the data from it.\n",
    "    inArray = root2array(inFilepath, branches=branchList, treename=inTreeName)\n",
    "    inFile = ROOT.TFile.Open(inFilepath)\n",
    "    inTree = inFile.Get(inTreeName)\n",
    "    print(\"Processing\", inFilepath, len(inArray), \"events found\")\n",
    "    nnFilepath = nnLocation + \"/nn_all_jets_noTags_boostedall_jets_LR5e-05.h5\"\n",
    "    scalerFilepath = nnLocation + \"/scaler_boostedall_jets_LR5e-05.sav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Silly hack to remove stuctured dtype\n",
    "    inDF = pandas.DataFrame(inArray)\n",
    "    run_sample_sf = inDF.pop(\"mc_sf\")\n",
    "    inArray = inDF.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # Scale input features to mean=0, stddev=1\n",
    "    scaler = joblib.load(scalerFilepath)\n",
    "    inArray = scaler.fit_transform(inArray)\n",
    "    model = keras.models.load_model(nnFilepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    scores = model.predict(inArray,batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23598132, 0.6636431 , 0.10037559],\n",
       "       [0.48547456, 0.19615498, 0.31837043],\n",
       "       [0.17034453, 0.7697709 , 0.05988456],\n",
       "       ...,\n",
       "       [0.03088052, 0.96418047, 0.00493904],\n",
       "       [0.59658056, 0.0399632 , 0.3634562 ],\n",
       "       [0.3124555 , 0.67703336, 0.0105111 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
