{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../train_and_append_boosted.py\n",
    "import statistics\n",
    "import collections\n",
    "import getopt, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linspace\n",
    "import pandas\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import root_numpy\n",
    "from ROOT import gSystem\n",
    "from root_numpy import root2array, array2tree\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import plot_model\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDict(collections.OrderedDict):\n",
    "    def __missing__(self, key):\n",
    "        val = self[key] = MyDict()\n",
    "        return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendListLocation = \"../datasets_to_append/\"\n",
    "nnLocation = \"./\"\n",
    "\n",
    "branchList = [\"pT_hh\",\n",
    "              \"nMuon\", \"nElec\",\n",
    "              \"h1_M\", \"h1_Pt\", \"h1_Eta\", \"h1_Phi\", \"h1_j1_j2_dR\",\n",
    "              \"h2_M\", \"h2_Pt\", \"h2_Eta\", \"h2_Phi\", \"h2_j1_j2_dR\",\n",
    "              \"met_Et\", \"met_Phi\", \n",
    "              \"h1_j1_BTag\",\"h1_j2_BTag\",\"h2_j1_BTag\",\"h2_j2_BTag\",\n",
    "              \"mc_sf\"]\n",
    "nFeatures = len(branchList)-1\n",
    "\n",
    "\n",
    "# Name of the tree we want to use\n",
    "inTreeName = \"preselection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for analysis in [\"resolved\", \"intermediate\", \"boosted\"]:\n",
    "analysis = \"intermediate\"\n",
    "inFileList = \"tst_sig_intermediate.txt\"\n",
    "\n",
    "branchList = [\"pT_hh\",\n",
    "              \"nMuon\", \"nElec\",\n",
    "              \"h1_M\", \"h1_Pt\", \"h1_Eta\", \"h1_Phi\", \"h1_j1_j2_dR\",\n",
    "              \"h2_M\", \"h2_Pt\", \"h2_Eta\", \"h2_Phi\", \"h2_j1_j2_dR\",\n",
    "              \"met_Et\", \"met_Phi\", \n",
    "              \"h1_j1_BTag\",\"h1_j2_BTag\",\"h2_j1_BTag\",\"h2_j2_BTag\",\n",
    "              \"mc_sf\"]\n",
    "nFeatures = len(branchList)-1    \n",
    "scoreBranch = MyDict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------array head             pT_hh  nMuon  nElec        h1_M       h1_Pt    h1_Eta    h1_Phi  \\\n",
      "6700   130.429830      0      0   83.836945  300.956085  1.705306  2.784479   \n",
      "11093   52.916580      0      0   77.851471  268.088440 -0.845061 -1.265199   \n",
      "5126     2.769688      0      0   90.263786  263.853302 -0.648472  1.650255   \n",
      "1356   128.295550      0      0  118.482887  253.944641  0.718268  0.421515   \n",
      "7467   345.712285      0      0  121.127342  406.262329  0.027286  3.050629   \n",
      "\n",
      "       h1_j1_j2_dR        h2_M       h2_Pt    h2_Eta    h2_Phi  h2_j1_j2_dR  \\\n",
      "6700      0.323660  269.609725  201.011523 -0.766970 -0.699505     1.884937   \n",
      "11093     1.572333  219.465773  217.792807 -0.822167  1.808314     1.782864   \n",
      "5126      0.603967  446.938056  266.398545 -0.173337 -1.487218     2.790592   \n",
      "1356      0.867205   83.071405  143.293231  0.640345 -3.062126     1.119389   \n",
      "7467      0.611357  247.595690   84.558608  1.556122 -0.787953     3.063598   \n",
      "\n",
      "          met_Et   met_Phi  h1_j1_BTag  h1_j2_BTag  h2_j1_BTag  h2_j2_BTag  \n",
      "6700   50.527138  0.175631           0           0           1           1  \n",
      "11093  52.503460  2.157998           0           0           0           1  \n",
      "5126   60.704338  2.000968           1           1           0           0  \n",
      "1356   41.374943 -3.063575           1           0           0           1  \n",
      "7467   14.084311 -1.603891           1           0           0           0  \n",
      "-------------------------array.values no mc_sf [[ 1.30429830e+02  0.00000000e+00  0.00000000e+00  8.38369446e+01\n",
      "   3.00956085e+02  1.70530593e+00  2.78447938e+00  3.23660364e-01\n",
      "   2.69609725e+02  2.01011523e+02 -7.66970279e-01 -6.99505214e-01\n",
      "   1.88493654e+00  5.05271378e+01  1.75630569e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  1.00000000e+00]\n",
      " [ 5.29165796e+01  0.00000000e+00  0.00000000e+00  7.78514709e+01\n",
      "   2.68088440e+02 -8.45061481e-01 -1.26519942e+00  1.57233332e+00\n",
      "   2.19465773e+02  2.17792807e+02 -8.22167286e-01  1.80831352e+00\n",
      "   1.78286392e+00  5.25034599e+01  2.15799761e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
      " [ 2.76968770e+00  0.00000000e+00  0.00000000e+00  9.02637863e+01\n",
      "   2.63853302e+02 -6.48472071e-01  1.65025520e+00  6.03966710e-01\n",
      "   4.46938056e+02  2.66398545e+02 -1.73336834e-01 -1.48721784e+00\n",
      "   2.79059236e+00  6.07043381e+01  2.00096774e+00  1.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.28295550e+02  0.00000000e+00  0.00000000e+00  1.18482887e+02\n",
      "   2.53944641e+02  7.18267977e-01  4.21515346e-01  8.67204682e-01\n",
      "   8.30714051e+01  1.43293231e+02  6.40344764e-01 -3.06212593e+00\n",
      "   1.11938933e+00  4.13749428e+01 -3.06357455e+00  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
      " [ 3.45712285e+02  0.00000000e+00  0.00000000e+00  1.21127342e+02\n",
      "   4.06262329e+02  2.72857100e-02  3.05062866e+00  6.11357247e-01\n",
      "   2.47595690e+02  8.45586085e+01  1.55612213e+00 -7.87952799e-01\n",
      "   3.06359821e+00  1.40843105e+01 -1.60389113e+00  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.56455442e+02  0.00000000e+00  0.00000000e+00  1.47712860e+02\n",
      "   3.67892365e+02  2.95251191e-01  2.40102768e+00  8.07894502e-01\n",
      "   2.76634041e+02  2.13592513e+02 -1.41925955e+00 -6.48202969e-01\n",
      "   2.16905743e+00  3.45639038e+01 -1.20965183e+00  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.57060237e+02  0.00000000e+00  0.00000000e+00  1.02710548e+02\n",
      "   4.22650085e+02  1.67441946e-02 -1.17723751e+00  1.19792730e+00\n",
      "   1.58301923e+02  1.26279957e+02  9.54833451e-01  1.07316771e+00\n",
      "   1.97832608e+00  1.49712601e+02  1.85123861e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 1.11116663e+02  0.00000000e+00  0.00000000e+00  1.18118927e+02\n",
      "   3.93004700e+02  1.54369712e-01  4.62031692e-01  7.45063539e-01\n",
      "   2.24603403e+02  2.84557380e+02  8.08692343e-01 -2.75197017e+00\n",
      "   1.36465886e+00  4.04873657e+01 -2.29835200e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 6.67906154e+01  0.00000000e+00  0.00000000e+00  1.46791840e+02\n",
      "   2.54228439e+02 -1.77796292e+00 -2.07533073e+00  1.06867695e+00\n",
      "   1.55801156e+02  2.91051186e+02 -1.53000842e+00  8.61050576e-01\n",
      "   1.01630080e+00  2.27683086e+01 -2.34911561e+00  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 7.65817648e+01  0.00000000e+00  0.00000000e+00  1.07994514e+02\n",
      "   2.96523743e+02 -1.16851354e+00  2.38753939e+00  7.36899653e-01\n",
      "   1.13096188e+02  2.35687512e+02 -3.86685780e-01 -9.30236397e-01\n",
      "   9.19695611e-01  2.72718735e+01  2.60721350e+00  1.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "-------------------------array after scaler [[-0.32921673 -0.03334843 -0.01504467 -0.27150027 -0.11402657  1.69734464\n",
      "   1.53832169 -1.22453401  0.84124446  0.14933235 -0.60124237 -0.38716245\n",
      "   0.64912563  0.17143438  0.09356952 -1.03011803 -1.01751607  0.94806546\n",
      "   1.05330091]\n",
      " [-1.15792234 -0.03334843 -0.01504467 -0.41969891 -0.65826744 -0.85064631\n",
      "  -0.69372831  1.78782409  0.47921386  0.37613276 -0.64466292  0.99776668\n",
      "   0.5044866   0.22316333  1.19025831 -1.03011803 -1.01751607 -1.05477948\n",
      "   1.05330091]\n",
      " [-1.69405016 -0.03334843 -0.01504467 -0.11237348 -0.72839523 -0.65424008\n",
      "   0.91317456 -0.54830964  2.12152411  1.03304326 -0.1342625  -0.82217243\n",
      "   1.93245886  0.43781599  1.10338595  0.97076255  0.98278547 -1.05477948\n",
      "  -0.94939631]\n",
      " [-0.35203463 -0.03334843 -0.01504467  0.58632351 -0.89246838  0.71122642\n",
      "   0.23593349  0.08673818 -0.50552971 -0.63073505  0.50581755 -1.69190678\n",
      "  -0.43567076 -0.06811838 -1.69842957  0.97076255 -1.01751607 -1.05477948\n",
      "   1.05330091]\n",
      " [ 1.9723998  -0.03334843 -0.01504467  0.65179947  1.62969318  0.02088802\n",
      "   1.68501444 -0.53048035  0.68230696 -1.42453825  1.22621091 -0.43600715\n",
      "   2.31931385 -0.78243296 -0.89090079  0.97076255 -1.01751607 -1.05477948\n",
      "  -0.94939631]\n",
      " [-0.05097307 -0.03334843 -0.01504467  1.31004941  0.99434182  0.28860381\n",
      "   1.3269757  -0.05634452  0.8919588   0.31936544 -1.11436366 -0.35883107\n",
      "   1.05173087 -0.2463929  -0.67279899  0.97076255 -1.01751607 -1.05477948\n",
      "  -0.94939631]\n",
      " [ 2.09372242 -0.03334843 -0.01504467  0.19580485  1.90105083  0.01035633\n",
      "  -0.6452466   0.88458917  0.03762152 -0.86067084  0.75320908  0.59178644\n",
      "   0.78146056  2.76754948  1.02055252  0.97076255  0.98278547  0.94806546\n",
      "  -0.94939631]\n",
      " [-0.53569665 -0.03334843 -0.01504467  0.57731196  1.41016593  0.1478536\n",
      "   0.25826477 -0.20792093  0.51630665  1.27846137  0.63824764 -1.52062496\n",
      "  -0.08811871 -0.09135013 -1.27509172 -1.03011803  0.98278547  0.94806546\n",
      "  -0.94939631]\n",
      " [-1.00959297 -0.03334843 -0.01504467  1.2872452  -0.88776909 -1.78267846\n",
      "  -1.1402461   0.57277947  0.01956642  1.36622569 -1.20148391  0.47464592\n",
      "  -0.58174937 -0.55513495 -1.30317526  0.97076255 -1.01751607 -1.05477948\n",
      "  -0.94939631]\n",
      " [-0.90491435 -0.03334843 -0.01504467  0.32663436 -0.18741978 -1.17379697\n",
      "   1.3195414  -0.22761588 -0.28875601  0.61798115 -0.30209278 -0.51458248\n",
      "  -0.71864093 -0.43725706  1.43877436  0.97076255  0.98278547 -1.05477948\n",
      "  -0.94939631]]\n",
      "-------------------------SCORES [[0.19554965 0.7498389  0.05461149]\n",
      " [0.26554155 0.32256484 0.4118936 ]\n",
      " [0.17134038 0.58297753 0.24568205]\n",
      " ...\n",
      " [0.13672896 0.34995112 0.5133199 ]\n",
      " [0.04574388 0.9456625  0.0085937 ]\n",
      " [0.7641287  0.1595025  0.07636882]]\n",
      "mean sig score =  0.289199344849176\n",
      "mean qcd score =  0.4201384523476554\n",
      "mean top score =  0.2906622026286626\n"
     ]
    }
   ],
   "source": [
    "nnFilepath = nnLocation + \"testingAppend.h5\"\n",
    "scalerFilepath = nnLocation + \"scaler_testingAppend.sav\"\n",
    "\n",
    "inFilepath0 = \"/home/paredes/pheno/testnn/pheno_study/utilities/SplitROOT/OxHHPh_06May2019_MG5_262_Py8_14TeV_NNPDF30NLO_Dlph3_pp2hh_4b_HeavyHiggsTHDM_TopYuk_1.0_SlfCoup_1.0_merged_ntup.root.intermediate_0.root\"\n",
    "inFilepath1 = \"/home/paredes/pheno/testnn/pheno_study/utilities/SplitROOT/OxHHPh_06May2019_MG5_262_Py8_14TeV_NNPDF30NLO_Dlph3_pp2hh_4b_HeavyHiggsTHDM_TopYuk_1.0_SlfCoup_1.0_merged_ntup.root.intermediate_1.root\"\n",
    "inFilepath2 = \"/home/paredes/pheno/testnn/pheno_study/utilities/SplitROOT/OxHHPh_06May2019_MG5_262_Py8_14TeV_NNPDF30NLO_Dlph3_pp2hh_4b_HeavyHiggsTHDM_TopYuk_1.0_SlfCoup_1.0_merged_ntup.root.intermediate_2.root\"\n",
    "inFilepath3 = \"/home/paredes/pheno/testnn/pheno_study/utilities/SplitROOT/OxHHPh_06May2019_MG5_262_Py8_14TeV_NNPDF30NLO_Dlph3_pp2hh_4b_HeavyHiggsTHDM_TopYuk_1.0_SlfCoup_1.0_merged_ntup.root.intermediate_3.root\"\n",
    "\n",
    "# Load the input file and grab the data from it.\n",
    "inArray0 = root2array(inFilepath0, branches=branchList, treename=inTreeName)\n",
    "inArray1 = root2array(inFilepath1, branches=branchList, treename=inTreeName)\n",
    "inArray2 = root2array(inFilepath2, branches=branchList, treename=inTreeName)\n",
    "inArray3 = root2array(inFilepath3, branches=branchList, treename=inTreeName)\n",
    "#inFile = ROOT.TFile.Open(inFilepath)\n",
    "#inTree = inFile.Get(inTreeName)\n",
    "\n",
    "# Silly hack to remove stuctured dtype\n",
    "inDF0 = pandas.DataFrame(inArray0)\n",
    "inDF1 = pandas.DataFrame(inArray1)\n",
    "inDF2 = pandas.DataFrame(inArray2)\n",
    "inDF3 = pandas.DataFrame(inArray3)\n",
    "inDF = inDF0\n",
    "inDF = inDF.append(inDF1)\n",
    "inDF = inDF.append(inDF2)\n",
    "inDF = inDF.append(inDF3)\n",
    "\n",
    "inDF = shuffle(inDF)\n",
    "evtWeights = inDF.pop(\"mc_sf\")\n",
    "\n",
    "print (\"-------------------------array head\",inDF.head())\n",
    "\n",
    "inArray = inDF.values\n",
    "print(\"-------------------------array.values no mc_sf\", inArray[:10])\n",
    "\n",
    "# Scale input features to mean=0, stddev=1\n",
    "#scaler = joblib.load(scalerFilepath)\n",
    "scaler = StandardScaler().fit(inArray)\n",
    "inArray_scaled = scaler.fit_transform(inArray)\n",
    "\n",
    "print(\"-------------------------array after scaler\",inArray_scaled[:10])\n",
    "\n",
    "# Load the NN from file\n",
    "model = keras.models.load_model(nnFilepath)\n",
    "\n",
    "# Run validation sample through the NN\n",
    "scores = model.predict(inArray_scaled)\n",
    "print(\"-------------------------SCORES\",scores)\n",
    "\n",
    "# Gonvert to 1D basig python aggays\n",
    "# 0 == signal; 1 == qcd; 2 == ttbar\n",
    "scores_sig = scores[:,0].tolist()\n",
    "scores_qcd = scores[:,1].tolist()\n",
    "scores_top = scores[:,2].tolist()\n",
    "print(\"mean sig score = \", statistics.mean(scores_sig))\n",
    "print(\"mean qcd score = \", statistics.mean(scores_qcd))\n",
    "print(\"mean top score = \", statistics.mean(scores_top))\n",
    "# Give it the correct numpy array structure for a branch\n",
    "scoreBranch[\"sig\"] = np.array(scores_sig, dtype=[('nnscore_sig', np.float32)])\n",
    "scoreBranch[\"qcd\"] = np.array(scores_qcd, dtype=[('nnscore_qcd', np.float32)])\n",
    "scoreBranch[\"top\"] = np.array(scores_top, dtype=[('nnscore_top', np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled pt_hh mean 2.4882030386680003e-17\n",
      "pt_hh mean 161.2232244582874\n"
     ]
    }
   ],
   "source": [
    "scaled_mean = statistics.mean(inArray_scaled[:,0])\n",
    "print(\"scaled pt_hh mean\",scaled_mean)\n",
    "print(\"pt_hh mean\",statistics.mean(inArray[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal score mean =  0.289199344849176\n",
      "   QCD score mean =  0.4201384523476554\n",
      " ttbar score mean =  0.2906622026286626\n"
     ]
    }
   ],
   "source": [
    "# Format data for convenience\n",
    "appendData = pandas.DataFrame(inArray)\n",
    "appendData['sig_score'] = pandas.Series(scores[:,0], index=appendData.index)\n",
    "appendData['qcd_score'] = pandas.Series(scores[:,1], index=appendData.index)\n",
    "appendData['top_score'] = pandas.Series(scores[:,2], index=appendData.index)\n",
    "\n",
    "\n",
    "print(\"signal score mean = \", statistics.mean(appendData['sig_score']))\n",
    "print(\"   QCD score mean = \", statistics.mean(appendData['qcd_score']))\n",
    "print(\" ttbar score mean = \", statistics.mean(appendData['top_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'1/N dN/d(NN Score)')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_params = {'density': True, 'bins': 50, 'linewidth': 2}\n",
    "min_value = 0\n",
    "max_value = 1\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(appendData['sig_score'], color=[\"r\"], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(appendData['qcd_score'], color=[\"b\"], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(appendData['top_score'], color=[\"g\"], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"signal score\",fontsize=20)\n",
    "plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nFeatures = len(branchList)-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program trains a neural network based on input numpy array files.\n",
    "# Output is one trained NN file (nn_*.h5) and one scaler file (scaler_*.sav)\n",
    "# per analysis. Optionally also makes plots of the output distributions for the\n",
    "# training sample.\n",
    "\n",
    "### NOTE this program uses 0.2 of the data as a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the directory whit lits of ntuples to append score to\n",
    "fileListLocation = \"test_append.txt\"\n",
    "# Path of the directory containing .npz files to train on.\n",
    "# Standard naming convention is assumed (e.g. \"trainingData_resolved.npz\")\n",
    "trainingDataPath = \"../train_all_jets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "numEpochs = 10\n",
    "batchSize = 100\n",
    "dropoutFraction = 0.3\n",
    "# initial learning rate for adamax\n",
    "init_lr = MyDict()\n",
    "init_lr[\"boosted\"] = 5e-5\n",
    "init_lr[\"intermediate\"] = 5e-3\n",
    "init_lr[\"resolved\"] = 5e-3\n",
    "\n",
    "# store parameters of the network in a string\n",
    "#param_string = \"_w_OPadamaxEP\"+str(numEpochs)+\"BS\"+str(batchSize)+\"DO\"+str(dropoutFraction).replace(\".\",\"\")\n",
    "# Plot score distributions for the training sample?\n",
    "makePlots = False\n",
    "\n",
    "target_nevents = 100000\n",
    "\n",
    "signal_weight = MyDict()\n",
    "ttbar_weight = MyDict()\n",
    "qcd_weight = MyDict()\n",
    "analysis = \"intermediate\"\n",
    "param_string = \"testSave_all_jets_LR\"+str(init_lr[analysis]).replace(\"0.\",\"0p\")\n",
    "print (\"paramters string \"+param_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input file and grab the data from it.\n",
    "# Label each type of background\n",
    "# Calculate weight for each 'target' sample\n",
    "#inFile = np.load(trainingDataPath + \"/trainingData_all_jets_\" + analysis + \".npz\")\n",
    "\n",
    "signalData = pandas.DataFrame(dat_sig)\n",
    "#signalData = pandas.DataFrame(inFile[\"sig\"])\n",
    "signalData[\"target\"] = 0\n",
    "#signal_weight[analysis] = target_nevents/len(signalData)\n",
    "print(len(signalData),\"(\",signal_weight[analysis],\") signal (weight) events found\")\n",
    "n_sig = len(signalData)\n",
    "\n",
    "signalAppendData = pandas.DataFrame(datAppend_sig)\n",
    "signalAppendData[\"target\"] = 0\n",
    "print(len(signalAppendData),\"(\",signal_weight[analysis],\") signal (weight) events found\")\n",
    "n_sig = len(signalAppendData)\n",
    "signal_weight[analysis] = target_nevents/(len(signalData)+len(signalAppendData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroundData = pandas.DataFrame(dat_4b)\n",
    "backgroundData[\"target\"] = 1\n",
    "\n",
    "backgroundAppend_4bData = pandas.DataFrame(datAppend_4b)\n",
    "backgroundAppend_4bData[\"target\"] = 1\n",
    "backgroundData = backgroundData.append(backgroundAppend_4bData)\n",
    "print(len(backgroundData), \"4b background events found\")\n",
    "\n",
    "backgroundAppend_2b2j = pandas.DataFrame(datAppend_2b2j)\n",
    "backgroundAppend_2b2j[\"target\"] = 1\n",
    "backgroundData = backgroundData.append(backgroundAppend_2b2j)\n",
    "\n",
    "background_2b2j = pandas.DataFrame(dat_2b2j)\n",
    "background_2b2j[\"target\"] = 1\n",
    "backgroundData = backgroundData.append(background_2b2j)\n",
    "print(len(background_2b2j)+len(backgroundAppend_2b2j), \"2b2j background events found\")\n",
    "\n",
    "n_qcd_bkg = len(backgroundData)+len(backgroundAppend_4bData)+len(background_2b2j)+len(backgroundAppend_2b2j)\n",
    "qcd_weight[analysis] = target_nevents/n_qcd_bkg\n",
    "print(n_qcd_bkg,\"(\",qcd_weight[analysis], \") qcd (weight) background events found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_ttbar = pandas.DataFrame(dat_ttbar)\n",
    "#background_ttbar = pandas.DataFrame(inFile[\"bkg_ttbar\"])\n",
    "background_ttbar[\"target\"] = 2\n",
    "ttbar_weight[analysis] = target_nevents/len(background_ttbar)\n",
    "print(len(background_ttbar),\"(\",ttbar_weight[analysis], \") ttbar (weight) background events found\")\n",
    "backgroundData = backgroundData.append(background_ttbar)\n",
    "n_ttbar = len(background_ttbar)\n",
    "\n",
    "backgroundAppend_ttbar = pandas.DataFrame(datAppend_ttbar)\n",
    "backgroundAppend_ttbar[\"target\"] = 2\n",
    "n_ttbar = len(background_ttbar)+len(backgroundAppend_ttbar)\n",
    "ttbar_weight[analysis] = target_nevents/n_ttbar\n",
    "print(n_ttbar,\"(\",ttbar_weight[analysis], \") ttbar (weight) background events found\")\n",
    "backgroundData = backgroundData.append(backgroundAppend_ttbar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = signalData.append(backgroundData, ignore_index = True)\n",
    "\n",
    "# Set all event weights to 1 by default\n",
    "allData.loc[:, 'mc_sf'] = 1.\n",
    "# Apply manual event weighting: numbers that give \"reasonable behavior\"\n",
    "allData.loc[allData.target == 0, 'mc_sf'] = signal_weight[analysis] # signal\n",
    "allData.loc[allData.target == 1, 'mc_sf'] = qcd_weight[analysis]    # QCD\n",
    "allData.loc[allData.target == 2, 'mc_sf'] = ttbar_weight[analysis]  # ttbar\n",
    "\n",
    "allData = shuffle(allData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainData = allData\n",
    "procType = xTrainData.pop(\"target\")\n",
    "\n",
    "\n",
    "X_train, X_run, yTypeTrain, yTypeRun = train_test_split(xTrainData, procType, test_size=0.4, random_state=1)\n",
    "X_train, X_test, yTypeTrain, yTypeTest = train_test_split(X_train, yTypeTrain, test_size=0.2, random_state=1)\n",
    "\n",
    "# These aren't input features, separate them out.\n",
    "evtWeightsTrain = X_train.pop(\"mc_sf\")\n",
    "evtWeightsVal = X_test.pop(\"mc_sf\")\n",
    "evtWeightsRun = X_run.pop(\"mc_sf\")\n",
    "\n",
    "# Convert pandas dataframes into numpy arrays\n",
    "X_test = X_test.values\n",
    "X_train = X_train.values\n",
    "X_run = X_run.values\n",
    "evtWeightsTrain = evtWeightsTrain.values\n",
    "evtWeightsVal = evtWeightsVal.values\n",
    "evtWeightsRun = evtWeightsRun.values\n",
    "y_test = keras.utils.to_categorical(yTypeTest, num_classes=3)\n",
    "y_train = keras.utils.to_categorical(yTypeTrain, num_classes=3)\n",
    "yTypeTest = yTypeTest.values\n",
    "yTypeTrain = yTypeTrain.values\n",
    "yTypeRun = yTypeRun.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(yTypeTrain,return_counts=True))\n",
    "print(np.unique(yTypeTest,return_counts=True))\n",
    "print(np.unique(yTypeRun,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this into the right format for keras\n",
    "\n",
    "# Scale input features to mean=0, stddev=1\n",
    "classStd1 = StandardScaler().fit(X_train)\n",
    "X_train = classStd1.fit_transform(X_train)\n",
    "X_test = classStd1.fit_transform(X_test)\n",
    "# scale run later\n",
    "#X_run = classStd1.fit_transform(X_run)\n",
    "#joblib.dump(classStd1, \"scaler_\" + analysis + param_string +\".sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the NN architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(200, activation=\"relu\", input_dim= nFeatures))#input_dim should be as long as the branchList given to the NN\n",
    "model.add(Dropout(dropoutFraction))\n",
    "model.add(Dense(200, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\")) # output nodes\n",
    "\n",
    "model.compile(\n",
    "        loss='categorical_crossentropy',  # we train 10-way classification\n",
    "        optimizer=keras.optimizers.adamax(lr=init_lr[analysis]),  # for SGD\n",
    "        metrics=['acc']  # report accuracy during training\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NN\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=numEpochs, batch_size=batchSize, sample_weight=evtWeightsTrain,shuffle=True)\n",
    "# no need to save model for now \n",
    "model.save(\"testingAppend.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training sample back through the NN\n",
    "probTrain = model.predict(X_train)\n",
    "probTest = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct discriminant\n",
    "scores_train = np.log(probTrain[:,0]/(probTrain[:,1]+probTrain[:,2]))\n",
    "scores_test = np.log(probTest[:,0]/(probTest[:,1]+probTest[:,2]))\n",
    "\n",
    "# Format data for convenience\n",
    "trainData = pandas.DataFrame(X_train)\n",
    "trainData['sig_score'] = pandas.Series(probTrain[:,0], index=trainData.index)\n",
    "trainData['qcd_score'] = pandas.Series(probTrain[:,1], index=trainData.index)\n",
    "trainData['top_score'] = pandas.Series(probTrain[:,2], index=trainData.index)\n",
    "trainData['disc'] = pandas.Series(scores_train, index=trainData.index)\n",
    "trainData['weight'] = pandas.Series(evtWeightsTrain, index=trainData.index)\n",
    "trainData['process'] = pandas.Series(yTypeTrain, index=trainData.index)\n",
    "\n",
    "print(\"signal mean = \", statistics.mean(trainData[trainData.process == 0]['sig_score']))\n",
    "print(\"   QCD mean = \", statistics.mean(trainData[trainData.process == 1]['sig_score']))\n",
    "print(\" ttbar mean = \", statistics.mean(trainData[trainData.process == 2]['sig_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pandas.DataFrame(X_test)\n",
    "testData['sig_score'] = pandas.Series(probTest[:,0], index=testData.index)\n",
    "testData['qcd_score'] = pandas.Series(probTest[:,1], index=testData.index)\n",
    "testData['top_score'] = pandas.Series(probTest[:,2], index=testData.index)\n",
    "testData['disc'] = pandas.Series(scores_test, index=testData.index)\n",
    "testData['weight'] = pandas.Series(evtWeightsVal, index=testData.index)\n",
    "testData['process'] = pandas.Series(yTypeTest, index=testData.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of signal score on validation data\n",
    "hist_params = {'density': True, 'bins': 50, 'linewidth': 2}\n",
    "min_value = 0\n",
    "max_value = 1\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(trainData[trainData.process == 0]['sig_score'], color=[\"r\"], weights=trainData[trainData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(trainData[trainData.process == 1]['sig_score'], color=[\"b\"], weights=trainData[trainData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(trainData[trainData.process == 2]['sig_score'], color=[\"g\"], weights=trainData[trainData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.hist(testData[testData.process == 0]['sig_score'], color=[\"r\"], linestyle = \"dotted\", weights=testData[testData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(testData[testData.process == 1]['sig_score'], color=[\"b\"], linestyle = \"dotted\", weights=testData[testData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(testData[testData.process == 2]['sig_score'], color=[\"g\"], linestyle = \"dotted\", weights=testData[testData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"signal score\",fontsize=20)\n",
    "plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)\n",
    "#plt.yscale('log')\n",
    "plt.title(analysis + \" (training and validation samples)\")\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(trainData[trainData.process == 0]['qcd_score'], color=[\"r\"], weights=trainData[trainData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(trainData[trainData.process == 1]['qcd_score'], color=[\"b\"], weights=trainData[trainData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(trainData[trainData.process == 2]['qcd_score'], color=[\"g\"], weights=trainData[trainData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.hist(testData[testData.process == 0]['qcd_score'], color=[\"r\"], linestyle = \"dotted\", weights=testData[testData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal(Val)', **hist_params)\n",
    "plt.hist(testData[testData.process == 1]['qcd_score'], color=[\"b\"], linestyle = \"dotted\", weights=testData[testData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD(Val)', **hist_params)\n",
    "plt.hist(testData[testData.process == 2]['qcd_score'], color=[\"g\"], linestyle = \"dotted\", weights=testData[testData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar(Val)', **hist_params)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"qcd score\",fontsize=20)\n",
    "plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signalAppendData = pandas.DataFrame(datAppend_sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(yTypeRun,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##append_mc_sf = signalAppendData.pop(\"mc_sf\")\n",
    "#append_mc_sf = X_run.pop(\"mc_sf\")\n",
    "#append_mc_sf = append_mc_sf.values\n",
    "## Convert pandas dataframes into numpy arrays\n",
    "## signalAppendData = signalAppendData.values\n",
    "#X_run = X_run.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_run_clone = X_run\n",
    "appendData_clone = pandas.DataFrame(X_run_clone)\n",
    "\n",
    "X_run = classStd1.fit_transform(X_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training sample back through the NN\n",
    "probAppend = model.predict(X_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data for convenience\n",
    "appendData = pandas.DataFrame(X_run)\n",
    "appendData['sig_score'] = pandas.Series(probAppend[:,0], index=appendData.index)\n",
    "appendData['qcd_score'] = pandas.Series(probAppend[:,1], index=appendData.index)\n",
    "appendData['top_score'] = pandas.Series(probAppend[:,2], index=appendData.index)\n",
    "appendData['weight'] = pandas.Series(evtWeightsRun, index=appendData.index)\n",
    "appendData['process'] = pandas.Series(yTypeRun, index=appendData.index)\n",
    "\n",
    "\n",
    "print(\"signal score mean = \", statistics.mean(appendData['sig_score']))\n",
    "print(\"   QCD score mean = \", statistics.mean(appendData['qcd_score']))\n",
    "print(\" ttbar score mean = \", statistics.mean(appendData['top_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probAppend[:,2]\n",
    "len(appendData[appendData.process == 2])\n",
    "print(np.unique(yTypeRun,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of signal score on validation data\n",
    "hist_params = {'density': True, 'bins': 50, 'linewidth': 2}\n",
    "min_value = 0\n",
    "max_value = 1\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(appendData[appendData.process == 0]['sig_score'], color=[\"r\"], weights=appendData[appendData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 1]['sig_score'], color=[\"b\"], weights=appendData[appendData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 2]['sig_score'], color=[\"g\"], weights=appendData[appendData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"signal score\",fontsize=20)\n",
    "plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)\n",
    "#plt.yscale('log')\n",
    "plt.title(analysis + \" (training and validation samples)\")\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(appendData[appendData.process == 0]['qcd_score'], color=[\"r\"], weights=appendData[appendData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 1]['qcd_score'], color=[\"b\"], weights=appendData[appendData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 2]['qcd_score'], color=[\"g\"], weights=appendData[appendData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"qcd score\",fontsize=20)\n",
    "plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.hist2d(appendData[appendData.process == 0]['sig_score'],appendData[appendData.process == 0][4],bins=(50,50),cmap=plt.cm.jet)\n",
    "plt.xlabel(\"signal score\",fontsize=20)\n",
    "plt.ylabel(\"leading higgs candidate mass\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendData_clone['process'] = pandas.Series(yTypeRun, index=appendData.index)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.hist2d(appendData[appendData.process == 0]['sig_score'],appendData_clone[appendData_clone.process == 0][3],bins=(50,50),cmap=plt.cm.jet)\n",
    "plt.xlabel(\"signal score\",fontsize=20)\n",
    "plt.ylabel(\"leading higgs candidate mass\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"nn_vs_h1M_signal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendData_clone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for analysis in [\"boosted\", \"intermediate\", \"resolved\"]:\n",
    "inFileList = fileListLocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the list of ntuple files we want to append and loop over them.\n",
    "f = open(inFileList,\"r\")\n",
    "for line in f:\n",
    "    # create a dictionary to store scores for all networks and event types\n",
    "    scoreBranch = MyDict()\n",
    "\n",
    "    inFilepath = line.rstrip()\n",
    "\n",
    "    # Load the input file and grab the data from it.\n",
    "    inArray = root2array(inFilepath, branches=branchList, treename=inTreeName)\n",
    "    inFile = ROOT.TFile.Open(inFilepath)\n",
    "    inTree = inFile.Get(inTreeName)\n",
    "    print(\"Processing\", inFilepath, len(inArray), \"events found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Silly hack to remove stuctured dtype\n",
    "    inDF = pandas.DataFrame(inArray)\n",
    "    run_sample_sf = inDF.pop(\"mc_sf\")\n",
    "    inArray = inDF.values\n",
    "\n",
    "    # Scale input features to mean=0, stddev=1\n",
    "    inArray = classStd1.fit_transform(inArray)\n",
    "\n",
    "    # Load the NN from file\n",
    "\n",
    "    # Run validation sample through the NN\n",
    "    scores = model.predict(inArray,batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    analysisData = pandas.DataFrame(inArray)\n",
    "    analysisData['sig_score'] = pandas.Series(scores[:,0], index=analysisData.index)\n",
    "    analysisData['qcd_score'] = pandas.Series(scores[:,1], index=analysisData.index)\n",
    "    analysisData['top_score'] = pandas.Series(scores[:,2], index=analysisData.index)\n",
    "    \n",
    "    print(\"mean sig score = \", statistics.mean(scores[:,0].tolist()))\n",
    "    print(\"mean qcd score = \", statistics.mean(scores[:,1].tolist()))\n",
    "    print(\"mean top score = \", statistics.mean(scores[:,2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of signal score on validation data\n",
    "hist_params = {'density': True, 'bins': 50, 'linewidth': 2}\n",
    "min_value = 0\n",
    "max_value = 1\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(appendData[appendData.process == 0]['sig_score'], color=[\"r\"], weights=appendData[appendData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 1]['sig_score'], color=[\"b\"], weights=appendData[appendData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 2]['sig_score'], color=[\"g\"], weights=appendData[appendData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"signal score\",fontsize=20)\n",
    "plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)\n",
    "#plt.yscale('log')\n",
    "plt.title(analysis + \" (training and validation samples)\")\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(appendData[appendData.process == 0]['qcd_score'], color=[\"r\"], weights=appendData[appendData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 1]['qcd_score'], color=[\"b\"], weights=appendData[appendData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "plt.hist(appendData[appendData.process == 2]['qcd_score'], color=[\"g\"], weights=appendData[appendData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"qcd score\",fontsize=20)\n",
    "plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Convert to 1D basic python arrays\n",
    "    # 0 == signal; 1 == qcd; 2 == ttbar\n",
    "    scores_sig = scores[:,0].tolist()\n",
    "    scores_qcd = scores[:,1].tolist()\n",
    "    scores_top = scores[:,2].tolist()\n",
    "    print(\"mean sig score = \", statistics.mean(scores_sig))\n",
    "    print(\"mean qcd score = \", statistics.mean(scores_qcd))\n",
    "    print(\"mean top score = \", statistics.mean(scores_top))\n",
    "    # Give it the correct numpy array structure for a branch\n",
    "    scoreBranch[\"sig\"] = np.array(scores_sig, dtype=[('nnscore_sig', np.float32)])\n",
    "    scoreBranch[\"qcd\"] = np.array(scores_qcd, dtype=[('nnscore_qcd', np.float32)])\n",
    "    scoreBranch[\"top\"] = np.array(scores_top, dtype=[('nnscore_top', np.float32)])\n",
    "\n",
    "    # Create output file\n",
    "    outFilepath = inFilepath.replace(\".root\", \"_withNNs.root\").split('/')[-1]\n",
    "    #print(\"Writing output to\", outFilepath)\n",
    "    outFile = ROOT.TFile(outFilepath, 'recreate')\n",
    "    # Make a copy of the input tree\n",
    "    outTree = inTree.CloneTree()\n",
    "    # Add our NN score branch to the copy\n",
    "    array2tree(scoreBranch[\"sig\"], tree=outTree)\n",
    "    array2tree(scoreBranch[\"qcd\"], tree=outTree)\n",
    "    array2tree(scoreBranch[\"top\"], tree=outTree)\n",
    "    # Write the augmented tree to output file\n",
    "    outTree.Write()\n",
    "\n",
    "    inFile.Close()\n",
    "    outFile.Close()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot accuracy and loss \n",
    "# plt.figure(figsize=(16, 8))\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title(analysis + ', model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.savefig(\"training/acc_\" + analysis +\"_\"+ param_string +\".png\")\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title(analysis + ', model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.savefig(\"training/loss_\" + analysis +\"_\"+ param_string +\".png\")\n",
    "\n",
    "# Optionally, plot the output distributions for the training sample.\n",
    "if makePlots:\n",
    "    # Run training sample back through the NN\n",
    "    probTrain = model.predict(X_train)\n",
    "    probTest = model.predict(X_test)\n",
    "\n",
    "    # Construct discriminant\n",
    "    scores_train = np.log(probTrain[:,0]/(probTrain[:,1]+probTrain[:,2]))\n",
    "    scores_test = np.log(probTest[:,0]/(probTest[:,1]+probTest[:,2]))\n",
    "\n",
    "    # Format data for convenience\n",
    "    trainData = pandas.DataFrame(X_train)\n",
    "    trainData['sig_score'] = pandas.Series(probTrain[:,0], index=trainData.index)\n",
    "    trainData['qcd_score'] = pandas.Series(probTrain[:,1], index=trainData.index)\n",
    "    trainData['top_score'] = pandas.Series(probTrain[:,2], index=trainData.index)\n",
    "    trainData['disc'] = pandas.Series(scores_train, index=trainData.index)\n",
    "    trainData['weight'] = pandas.Series(evtWeightsTrain, index=trainData.index)\n",
    "    trainData['process'] = pandas.Series(yTypeTrain, index=trainData.index)\n",
    "\n",
    "    print(\"signal mean = \", statistics.mean(trainData[trainData.process == 0]['sig_score']))\n",
    "    print(\"   QCD mean = \", statistics.mean(trainData[trainData.process == 1]['sig_score']))\n",
    "    print(\" ttbar mean = \", statistics.mean(trainData[trainData.process == 2]['sig_score']))\n",
    "\n",
    "    testData = pandas.DataFrame(X_test)\n",
    "    testData['sig_score'] = pandas.Series(probTest[:,0], index=testData.index)\n",
    "    testData['qcd_score'] = pandas.Series(probTest[:,1], index=testData.index)\n",
    "    testData['top_score'] = pandas.Series(probTest[:,2], index=testData.index)\n",
    "    testData['disc'] = pandas.Series(scores_test, index=testData.index)\n",
    "    testData['weight'] = pandas.Series(evtWeightsVal, index=testData.index)\n",
    "    testData['process'] = pandas.Series(yTypeTest, index=testData.index)\n",
    "\n",
    "    # Plot distributions of signal score on validation data\n",
    "    hist_params = {'density': True, 'bins': 50, 'linewidth': 2}\n",
    "    min_value = 0\n",
    "    max_value = 1\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.hist(trainData[trainData.process == 0]['sig_score'], color=[\"r\"], weights=trainData[trainData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 1]['sig_score'], color=[\"b\"], weights=trainData[trainData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 2]['sig_score'], color=[\"g\"], weights=trainData[trainData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "    plt.hist(testData[testData.process == 0]['sig_score'], color=[\"r\"], linestyle = \"dotted\", weights=testData[testData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "    plt.hist(testData[testData.process == 1]['sig_score'], color=[\"b\"], linestyle = \"dotted\", weights=testData[testData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "    plt.hist(testData[testData.process == 2]['sig_score'], color=[\"g\"], linestyle = \"dotted\", weights=testData[testData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"signal score\",fontsize=20)\n",
    "    plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)\n",
    "    #plt.yscale('log')\n",
    "    plt.title(analysis + \" (training and validation samples)\")\n",
    "    plt.savefig(\"sig_scores_\" + analysis + param_string +\".png\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.hist(trainData[trainData.process == 0]['qcd_score'], color=[\"r\"], weights=trainData[trainData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 1]['qcd_score'], color=[\"b\"], weights=trainData[trainData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 2]['qcd_score'], color=[\"g\"], weights=trainData[trainData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "    plt.hist(testData[testData.process == 0]['qcd_score'], color=[\"r\"], linestyle = \"dotted\", weights=testData[testData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal(Val)', **hist_params)\n",
    "    plt.hist(testData[testData.process == 1]['qcd_score'], color=[\"b\"], linestyle = \"dotted\", weights=testData[testData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD(Val)', **hist_params)\n",
    "    plt.hist(testData[testData.process == 2]['qcd_score'], color=[\"g\"], linestyle = \"dotted\", weights=testData[testData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar(Val)', **hist_params)\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"qcd score\",fontsize=20)\n",
    "    plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)\n",
    "    #plt.yscale('log')\n",
    "    plt.title(analysis + \", (training and validation samples)\")\n",
    "    plt.savefig(\"qcd_scores_\" + analysis + param_string +\".png\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.hist(trainData[trainData.process == 0]['top_score'], color=[\"r\"], weights=trainData[trainData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 1]['top_score'], color=[\"b\"], weights=trainData[trainData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 2]['top_score'], color=[\"g\"], weights=trainData[trainData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "    plt.hist(testData[testData.process == 0]['top_score'], color=[\"r\"], linestyle = \"dotted\", weights=testData[testData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal(Val)', **hist_params)\n",
    "    plt.hist(testData[testData.process == 1]['top_score'], color=[\"b\"], linestyle = \"dotted\", weights=testData[testData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD(val)', **hist_params)\n",
    "    plt.hist(testData[testData.process == 2]['top_score'], color=[\"g\"], linestyle = \"dotted\", weights=testData[testData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar(val)', **hist_params)\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"ttbar score\",fontsize=20)\n",
    "    plt.ylabel(\"1/N dN/d(NN Score)\",fontsize=20)\n",
    "    #plt.yscale('log')\n",
    "    plt.title(analysis + \", (training and validation samples)\")\n",
    "    plt.savefig(\"top_scores_\" + analysis + param_string +\".png\")\n",
    "\n",
    "    # Plot distributions of composite discriminant on training data\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(trainData[trainData.process == 0]['disc'], color=[\"r\"], weights=trainData[trainData.process == 0]['weight'], range=(min_value, max_value), histtype='step', label='Signal', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 1]['disc'], color=[\"b\"], weights=trainData[trainData.process == 1]['weight'], range=(min_value, max_value), histtype='step', label='QCD', **hist_params)\n",
    "    plt.hist(trainData[trainData.process == 2]['disc'], color=[\"g\"], weights=trainData[trainData.process == 2]['weight'], range=(min_value, max_value), histtype='step', label='ttbar', **hist_params)\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"Discriminant\",fontsize=20)\n",
    "    plt.ylabel(\"1/N dN/d(Discriminant)\",fontsize=20)\n",
    "    #plt.yscale('log')\n",
    "    plt.title(analysis + \", Discriminant (training sample)\")\n",
    "    plt.savefig(\"discs_\" + analysis + param_string +\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
